{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tm_SbCiKTG0W"
   },
   "outputs": [],
   "source": [
    "import torch, torchvision, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIE5m1hZmk6y"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1OOTqlIihNC"
   },
   "outputs": [],
   "source": [
    "import torch, numpy as np, random, os\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YsQHGieZTJJF"
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914,0.4822,0.4465),\n",
    "                                     (0.2023,0.1994,0.2010))\n",
    "])\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                         download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=256, shuffle=True,\n",
    "                          num_workers=2, pin_memory=True)\n",
    "\n",
    "test_set  = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                         download=True, transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qh3dG1LFTKjZ"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "model = torchvision.models.resnet18(\n",
    "    weights=ResNet18_Weights.IMAGENET1K_V1\n",
    ")\n",
    "model.fc = nn.Linear(512, 10)\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiWexueATPG-"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "opt  = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        opt.zero_grad(); loss = crit(model(x), y); loss.backward(); opt.step()\n",
    "    sched.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zeWi7ZzmTSyU",
    "outputId": "411fc29f-356f-44cd-ffbc-12ac0e9ae109"
   },
   "outputs": [],
   "source": [
    "def top1(net):\n",
    "    net.eval(); correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            pred = net(x).argmax(1)\n",
    "            correct += (pred == y).sum().item(); total += y.size(0)\n",
    "    return 100 * correct / total\n",
    "\n",
    "baseline_acc = top1(model)\n",
    "print(f\"Fine-tuned Top-1 = {baseline_acc:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i80S8gi6TZjX",
    "outputId": "30b22820-bbda-4f4d-df30-c4145d3943bf"
   },
   "outputs": [],
   "source": [
    "ckpt_path = \"res18_cifar10_finetuned.pt\"\n",
    "torch.save(model.state_dict(), ckpt_path)\n",
    "print(f\"Checkpoint saved to {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pfJR0VzTj7X",
    "outputId": "cb612c71-3b21-4e99-8c2c-54b30705c075"
   },
   "outputs": [],
   "source": [
    "import copy, torch, torchvision, torch.nn as nn\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ckpt_path = \"res18_cifar10_finetuned.pt\"\n",
    "\n",
    "\n",
    "base_clean = torchvision.models.resnet18(weights=None)\n",
    "base_clean.fc = nn.Linear(512, 10)\n",
    "base_clean.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))\n",
    "base_clean = base_clean.to(DEVICE).eval()\n",
    "\n",
    "def top1(net):\n",
    "    net.eval(); correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            pred = net(x).argmax(1)\n",
    "            correct += (pred == y).sum().item(); total += y.size(0)\n",
    "    return 100 * correct / total\n",
    "\n",
    "print(f\"Baseline check → Top-1 {top1(base_clean):.2f} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKMBCcwzVol9"
   },
   "outputs": [],
   "source": [
    "from torch import linalg as LA\n",
    "\n",
    "def compress_conv(conv: nn.Conv2d, rank: int) -> nn.Module:\n",
    "    k = conv.kernel_size[0]\n",
    "    if k == 1 or conv.stride != (1, 1) or conv.groups != 1:\n",
    "        return conv\n",
    "\n",
    "    OC, IC = conv.out_channels, conv.in_channels\n",
    "    Wm = conv.weight.data.reshape(OC, -1)\n",
    "\n",
    "\n",
    "    U, S, Vh = torch.linalg.svd(Wm.cpu(), full_matrices=False)\n",
    "    U_r  = U[:, :rank] * S[:rank].sqrt()\n",
    "    V_r  = (S[:rank].sqrt().unsqueeze(1) * Vh[:rank]) \\\n",
    "           .reshape(rank, IC, k, k)\n",
    "\n",
    "    device = conv.weight.device\n",
    "    conv_k = nn.Conv2d(\n",
    "        IC, rank, k,\n",
    "        padding=k // 2, stride=1, dilation=conv.dilation,\n",
    "        groups=1, bias=False, device=device)\n",
    "\n",
    "    conv_1 = nn.Conv2d(\n",
    "        rank, OC, 1,\n",
    "        padding=0,  stride=1, dilation=conv.dilation,\n",
    "        groups=1, bias=True,  device=device)\n",
    "\n",
    "\n",
    "    conv_k.weight.data.copy_(V_r.to(device))\n",
    "    conv_1.weight.data.copy_(U_r.to(device).unsqueeze(-1).unsqueeze(-1))\n",
    "    if conv.bias is not None:\n",
    "        conv_1.bias.data.copy_(conv.bias.data)\n",
    "    else:\n",
    "        conv_1.bias.data.zero_()\n",
    "\n",
    "    return nn.Sequential(conv_k, conv_1)\n",
    "\n",
    "\n",
    "def compress_model(base: nn.Module,\n",
    "                   energy: float = 0.99,\n",
    "                   return_rank: bool = False):\n",
    "    import copy, torch.nn as nn\n",
    "    from torch import linalg as LA\n",
    "\n",
    "    model = copy.deepcopy(base)\n",
    "    rank_map = {}\n",
    "\n",
    "    for name, m in list(model.named_modules()):\n",
    "        if isinstance(m, nn.Conv2d) and m.kernel_size[0] > 1:\n",
    "            S = LA.svdvals(m.weight.reshape(m.out_channels, -1))\n",
    "            cum = torch.cumsum(S**2, 0) / torch.sum(S**2)\n",
    "            r   = int((cum < energy).sum()) + 1\n",
    "            rank_map[name] = r\n",
    "\n",
    "            parent, child = name.rsplit('.',1) if '.' in name else ('', name)\n",
    "            tgt = model if parent == '' else dict(model.named_modules())[parent]\n",
    "            setattr(tgt, child, compress_conv(m, r))\n",
    "\n",
    "    return (model, rank_map) if return_rank else model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tBctYEqTVr4X",
    "outputId": "061a381f-942d-4e8b-c142-d4a5ab3a16ce"
   },
   "outputs": [],
   "source": [
    "model_99 = compress_model(copy.deepcopy(base_clean), 0.99).eval().to(DEVICE)\n",
    "\n",
    "acc_99 = top1(model_99)\n",
    "params_99 = sum(p.numel() for p in model_99.parameters()) / 1e6\n",
    "print(f\"SVD(99%) → Top-1 {acc_99:.2f} % · Params {params_99:.2f} M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MaEBIYoXVu2o",
    "outputId": "bf13b264-e25d-46a9-f040-2be06494e667"
   },
   "outputs": [],
   "source": [
    "energies = [0.99, 0.95, 0.90, 0.85, 0.80, 0.75]\n",
    "results  = []\n",
    "baseline_params = sum(p.numel() for p in base_clean.parameters()) / 1e6\n",
    "\n",
    "for e in energies:\n",
    "    m_c = compress_model(copy.deepcopy(base_clean), e).eval().to(DEVICE)\n",
    "    acc = top1(m_c)\n",
    "    params = sum(p.numel() for p in m_c.parameters()) / 1e6\n",
    "    comp_ratio = params / baseline_params\n",
    "    print(f\"SVD({e*100:.0f}%) → Top-1 {acc:.2f}% · {params:.2f} M params\")\n",
    "    results.append((e, comp_ratio, acc, params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "ic7DEBtoV6XQ",
    "outputId": "f06633be-97d3-467c-be39-3ef7297fb5ec"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "comp = [r[1] for r in results]\n",
    "acc  = [r[2] for r in results]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(comp, acc, marker='o', label='SVD-compressed')\n",
    "plt.scatter(1.0, results[0][2], color='red', label='Baseline')\n",
    "plt.xlabel('Compression Ratio (relative params)')\n",
    "plt.ylabel('Top-1 Accuracy (%)')\n",
    "plt.title('Compression vs Accuracy – ResNet-18 / CIFAR-10')\n",
    "plt.grid(True); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jM6xYcy4Wh1K"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_95, rank_dict95 = compress_model(base_clean, 0.95, return_rank=True)\n",
    "model_90, rank_dict90 = compress_model(base_clean, 0.90, return_rank=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFflHWnSahUk"
   },
   "outputs": [],
   "source": [
    "import torch, time\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def gpu_latency(model,\n",
    "                input_size=(256,3,224,224),\n",
    "                reps=200,\n",
    "                warmup=30):\n",
    "    \"\"\"\n",
    "    量測 GPU 推論延遲，回傳：毫秒 / 張\n",
    "    \"\"\"\n",
    "    model = model.to('cuda').eval()\n",
    "    x = torch.randn(*input_size, device='cuda')\n",
    "\n",
    "    # warm-up\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup):\n",
    "            _ = model(x)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    elapsed = 0.0\n",
    "    with torch.no_grad():\n",
    "        for _ in range(reps):\n",
    "            start.record()\n",
    "            _ = model(x)\n",
    "            end.record()\n",
    "            torch.cuda.synchronize()\n",
    "            elapsed += start.elapsed_time(end)\n",
    "\n",
    "    return elapsed / reps / input_size[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "7Shy9eEAaksk",
    "outputId": "a0c1a2d7-e753-482b-a28b-de550854befc"
   },
   "outputs": [],
   "source": [
    "# 1) 測速工具\n",
    "import torch, time, matplotlib.pyplot as plt\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def gpu_latency(model, input_size=(256,3,224,224), reps=200, warmup=30):\n",
    "    x = torch.randn(*input_size, device='cuda')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup):\n",
    "            _ = model(x)\n",
    "    torch.cuda.synchronize()\n",
    "    st, ed = torch.cuda.Event(True), torch.cuda.Event(True)\n",
    "    t = 0.0\n",
    "    with torch.no_grad():\n",
    "        for _ in range(reps):\n",
    "            st.record(); _ = model(x); ed.record()\n",
    "            torch.cuda.synchronize()\n",
    "            t += st.elapsed_time(ed)\n",
    "    return t / reps / input_size[0]\n",
    "\n",
    "energies   = [0.99, 0.95, 0.90, 0.85, 0.80, 0.75]\n",
    "model_bank = {'Baseline': torch.jit.script(base_clean).eval().to('cuda')}\n",
    "\n",
    "for e in energies:\n",
    "    mdl = compress_model(base_clean, e)\n",
    "    mdl = torch.jit.script(mdl).eval().to('cuda')     # ★ fuse kernels\n",
    "    model_bank[f'SVD-{int(e*100)}'] = mdl\n",
    "\n",
    "# 3) 測速\n",
    "records = []\n",
    "for name, mdl in model_bank.items():\n",
    "    ms = gpu_latency(mdl, (256,3,224,224))\n",
    "    records.append((name, ms))\n",
    "    print(f\"{name:<9}: {ms:.3f} ms/img\")\n",
    "\n",
    "# 4) 畫圖\n",
    "labels, vals = zip(*records)\n",
    "plt.figure(figsize=(6,3.5))\n",
    "plt.bar(labels, vals)\n",
    "plt.ylabel('ms / image (batch128)')\n",
    "plt.title('GPU Latency – ResNet-18 (TorchScript fused)')\n",
    "plt.grid(axis='y', ls=':')\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "twCRvks7brcC",
    "outputId": "9cf79f17-abda-4724-b571-7c9dd5505f27"
   },
   "outputs": [],
   "source": [
    "comp_ratio = [1.00, 0.99, 0.81, 0.68, 0.59]\n",
    "accs       = [83.8, 83.3, 79.6, 76.0, 67.5]\n",
    "gpu_lat_ms = [0.185, 0.123, 0.127, 0.143, 0.166]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6,4))\n",
    "ax1.plot(comp_ratio, accs, 'o-', color='tab:blue')\n",
    "ax1.set_xlabel('Compression Ratio')\n",
    "ax1.set_ylabel('Top-1 Acc (%)', color='tab:blue')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(comp_ratio, gpu_lat_ms, 's--', color='tab:red')\n",
    "ax2.set_ylabel('GPU latency (ms / img)', color='tab:red')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "fig.tight_layout(); plt.title('Accuracy vs GPU Latency vs Compression')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHtWW7Fh_JVm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
